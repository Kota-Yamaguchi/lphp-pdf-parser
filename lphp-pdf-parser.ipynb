{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!apt-get install -y libmagic-dev poppler-utils tesseract-ocr\n",
    "%pip install \"unstructured[pdf]\" unstructured langchain PyMuPDF openai langchain_openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "import os\n",
    "from getpass import getpass\n",
    "from langchain_openai import ChatOpenAI\n",
    "os.environ[\"OPENAI_API_KEY\"] = getpass()\n",
    "openai.api_key = os.environ[\"OPENAI_API_KEY\"]\n",
    "chat = ChatOpenAI(model=\"gpt-3.5-turbo-0125\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 本文を抽出"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from langchain_core.prompts import ChatPromptTemplate,MessagesPlaceholder\n",
    "from langchain_core.runnables.history import RunnableWithMessageHistory\n",
    "from langchain_community.chat_message_histories import ChatMessageHistory\n",
    "from langchain_core.chat_history import BaseChatMessageHistory\n",
    "from langchain_text_splitters import CharacterTextSplitter\n",
    "import fitz  # PyMuPDF\n",
    "\n",
    "def extract_text_from_pdf_range_and_save(pdf_path, output_file_path, start_page=None, end_page=None):\n",
    "    # PDFファイルを開く\n",
    "    doc = fitz.open(pdf_path)\n",
    "\n",
    "    # テキストを保持するための空の文字列を初期化\n",
    "    text = \"\"\n",
    "      # start_pageとend_pageが指定されていない場合、全ページを対象にする\n",
    "    if start_page is None or end_page is None:\n",
    "        start_page = 0\n",
    "        end_page = doc.page_count - 1\n",
    "\n",
    "    # 指定されたページ範囲内の各ページを反復処理\n",
    "    for page_num in range(start_page, end_page + 1):\n",
    "        # ページオブジェクトを取得\n",
    "        page = doc.load_page(page_num)\n",
    "\n",
    "        # ページからテキストを抽出\n",
    "        text += page.get_text()\n",
    "\n",
    "    # PDFドキュメントを閉じる\n",
    "    doc.close()\n",
    "\n",
    "    # 抽出したテキストをテキストファイルに保存\n",
    "    with open(output_file_path, 'w', encoding='utf-8') as f:\n",
    "        f.write(text)\n",
    "\n",
    "    print(f\"テキストがファイルに保存されました: {output_file_path}\")\n",
    "    return text\n",
    "\n",
    "def process_segments_with_langchain(segments):\n",
    "  store = {}\n",
    "\n",
    "  def get_session_history(session_id: str) -> BaseChatMessageHistory:\n",
    "      if session_id not in store:\n",
    "          store[session_id] = ChatMessageHistory()\n",
    "      return store[session_id]\n",
    "\n",
    "  system = (\n",
    "    \"You are an excellent text extractor. You remove headers, footers and figure captions that are not relevant to the body text. Don't skip the headline.The output is always the body text only, with no explanations.\"\n",
    "  )\n",
    "  human = \"{text}\"\n",
    "  prompt = ChatPromptTemplate.from_messages([(\"system\", system), MessagesPlaceholder(variable_name=\"chat_history\"), (\"human\", human),])\n",
    "   # RunnableWithMessageHistoryのインスタンスを作成\n",
    "  runnable = prompt | chat\n",
    "  with_message_history = RunnableWithMessageHistory(\n",
    "      runnable,\n",
    "      get_session_history,\n",
    "      input_messages_key=\"text\",\n",
    "      history_messages_key=\"chat_history\",\n",
    "  )\n",
    "  # 一意のセッションIDを指定\n",
    "  session_id = \"unique_session_id\"\n",
    "  processed_segments = []\n",
    "  for i, segment in enumerate(segments):\n",
    "    print(\"segment processed ....\")\n",
    "\n",
    "    response = with_message_history.invoke(\n",
    "          {\"text\": segment},\n",
    "          config={\"configurable\": {\"session_id\": session_id}},  # 一意のセッションIDを指定\n",
    "      )\n",
    "    processed_segments.append(response)\n",
    "    store[session_id].clear()\n",
    "    prememory=ChatMessageHistory()\n",
    "    prememory.add_user_message(segment)\n",
    "    prememory.add_ai_message(response.content)\n",
    "    store[session_id] = prememory\n",
    "\n",
    "\n",
    "  return processed_segments\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "output_file_path = './extracted_text.txt'  # 保存するテキストファイルのパス\n",
    "\n",
    "preprocess_text=extract_text_from_pdf_range_and_save(pdf_path, output_file_path)\n",
    "\n",
    "text_splitter = CharacterTextSplitter(\n",
    "    separator=\"\",\n",
    "    chunk_size=4096,\n",
    "    chunk_overlap=0,\n",
    "    length_function=len,\n",
    "    is_separator_regex=False,\n",
    ")\n",
    "segments = text_splitter.split_text(preprocess_text)\n",
    "processed_segments = process_segments_with_langchain(segments)\n",
    "final_text=\"\"\n",
    "for processed_segment in processed_segments:\n",
    "  final_text+= processed_segment.content\n",
    "\n",
    "# 処理されたテキストをファイルに保存\n",
    "output_file_path = 'final_processed_text.txt'  # 保存先のファイルパス\n",
    "with open(output_file_path, 'w', encoding='utf-8') as file:\n",
    "    file.write(final_text)\n",
    "\n",
    "print(f\"処理されたテキストが保存されました: {output_file_path}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 画像・表・キャプションの抽出"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from unstructured.partition.pdf import partition_pdf\n",
    "\n",
    "def extract_images_and_captions(filename):\n",
    "    \"\"\"\n",
    "    Extracts images and their captions from a given PDF file.\n",
    "\n",
    "    :param filename: The path to the PDF file.\n",
    "    :return: A tuple containing two lists - the first for images and the second for captions.\n",
    "    \"\"\"\n",
    "    elements = partition_pdf(filename=filename, strategy=\"hi_res\",\n",
    "                             extract_images_in_pdf=True,\n",
    "                             extract_image_block_types=[\"Image\",\"Table\"],\n",
    "                             extract_image_block_to_payload=False,\n",
    "                             extract_image_block_output_dir=\"./images\")\n",
    "\n",
    "    tables = [el for el in elements if el.category == \"Image\"]\n",
    "    caption = [el for el in elements if el.category == \"FigureCaption\" or el.text.lower().startswith((\"figure\", \"fig\"))]\n",
    "\n",
    "    return tables, caption\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf_path=\"./2402.12352.pdf\"\n",
    "images, captions = extract_images_and_captions(pdf_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def find_midpoint_from_corners(points):\n",
    "    \"\"\"四角形の座標から中心点を計算します。\"\"\"\n",
    "    x_coords = [p[0] for p in points]\n",
    "    y_coords = [p[1] for p in points]\n",
    "    center_x = sum(x_coords) / len(x_coords)\n",
    "    center_y = sum(y_coords) / len(y_coords)\n",
    "    return center_x, center_y\n",
    "\n",
    "def calculate_distance(center1, center2):\n",
    "    \"\"\"二点間の距離を計算します。\"\"\"\n",
    "    return ((center1[0] - center2[0]) ** 2 + (center1[1] - center2[1]) ** 2) ** 0.5\n",
    "\n",
    "def match_figures_to_captions(figures, captions):\n",
    "    \"\"\"図とキャプションを紐付けます。\"\"\"\n",
    "    matches = []\n",
    "    for image in images:\n",
    "      image_midpoint = find_midpoint_from_corners(image.metadata.coordinates.points)\n",
    "      closest_caption = None\n",
    "      closest_distance = float('inf')\n",
    "      for caption in captions:\n",
    "              # ページ番号が一致し、キャプションが図より下にあるか確認\n",
    "              if image.metadata.page_number == caption.metadata.page_number and \\\n",
    "                find_midpoint_from_corners(caption.metadata.coordinates.points)[1] > image_midpoint[1]:\n",
    "                  caption_midpoint = find_midpoint_from_corners(caption.metadata.coordinates.points)\n",
    "                  distance = calculate_distance(image_midpoint, caption_midpoint)\n",
    "                  if distance < closest_distance:\n",
    "                      closest_distance = distance\n",
    "                      closest_caption = caption\n",
    "      if closest_caption is not None:\n",
    "            matches.append((image.id, closest_caption.id))\n",
    "      else:\n",
    "            matches.append((image.id, None))\n",
    "    return matches\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import json\n",
    "\n",
    "def match_figures_and_captions_to_json(matches, images, captions, output_file_path):\n",
    "    output_json = []\n",
    "    for match in matches:\n",
    "        image_id, caption_id = match\n",
    "        image_info = next((item for item in images if item.id == image_id), None)\n",
    "        caption_info = next((item for item in captions if item.id == caption_id), None)\n",
    "        if image_info and getattr(image_info, 'category', None) == \"Image\":\n",
    "            # キャプションテキストから図番号を抽出\n",
    "            if caption_info:\n",
    "                search_result = re.search(r'^(fig|figure)\\s*(\\d+)', caption_info.text, re.IGNORECASE)\n",
    "                if search_result:\n",
    "                    figure_number = search_result.group(2)\n",
    "                    figure_name = f\"Figure {figure_number}\"\n",
    "                else:\n",
    "                    figure_name = \"Unknown Figure\"\n",
    "                caption_text = caption_info.text\n",
    "            else:\n",
    "                figure_name = \"Unknown Figure\"\n",
    "                caption_text = \"No Caption\"\n",
    "\n",
    "            figure_path = image_info.metadata.image_path\n",
    "            output_json.append({\n",
    "                \"id\": image_info.id,\n",
    "                \"category\": image_info.category,\n",
    "                \"name\": figure_name,\n",
    "                \"caption\": caption_text,\n",
    "                \"image_path\": figure_path,\n",
    "                \"image_text\": image_info.text,\n",
    "            })\n",
    "\n",
    "    with open(output_file_path, 'w', encoding='utf-8') as f:\n",
    "        json.dump(output_json, f, ensure_ascii=False, indent=4)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matches = match_figures_to_captions(images, captions)\n",
    "output_file_path = 'matched_figures_captions.json'\n",
    "match_figures_and_captions_to_json(matches, images, captions, output_file_path)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
