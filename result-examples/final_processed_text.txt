Large language models (LLMs) are transforming the way information is retrieved with vast amounts of knowledge being summarized and presented via natural language conversations. Yet, LLMs are prone to highlight the most frequently seen pieces of information from the training set and to neglect the rare ones. In the field of biomedical research, latest discoveries are key to academic and industrial actors and are obscured by the abundance of an ever-increasing literature corpus (the information overload problem). Surfacing new associations between biomedical entities, e.g., drugs, genes, diseases, with LLMs becomes a challenge of capturing the long-tail knowledge of the biomedical scientific production. To overcome this challenge, Retrieval Augmented Generation (RAG) has been proposed to alleviate some of the shortcomings of LLMs by augmenting the prompts with context retrieved from external datasets. RAG methods typically select the context via maximum similarity search over text embeddings. In this study, we show that RAG methods leave out a significant proportion of relevant information due to clusters of over-represented concepts in the biomedical literature. We introduce a novel information-retrieval method that leverages a knowledge graph to downsample these clusters and mitigate the information overload problem. Its retrieval performance is about twice better than embedding similarity alternatives on both precision and recall. Finally, we demonstrate that both embedding similarity and knowledge graph retrieval methods can be advantageously combined into a hybrid model that outperforms both, enabling potential improvements to biomedical question-answering models.

The field of biomedical research is expanding rapidly, leading to an accelerated pace of discoveries and an overwhelming surge in associated literature. Keeping track of the evolving landscape of this field is increasingly challenging for individuals. The diversity of the disciplines composing biomedical research, including molecular biology, pharmacology, clinical medicine, and epidemiology, demands an understanding of specialized terminologies and techniques that surpasses the capacity of a single individual. Amongst these disciplines, biochemistry stands out by generating a staggering number of unique entities, underlined by the indexing of over 42 million unique genes by the National Center for Biotechnology Information. These factors underscore the indispensable requirement for technologically advanced tools capable of filtering, summarizing, and elucidating this vast body of knowledge, thereby enhancing our understanding of biomedical research.

Recent years have seen breakthroughs in Large Language Models (LLMs), which have been instrumental in developing diverse applications such as question answering (QA), text summarization, language translation, and creative text generation. Amongst the methods used for producing user answers, two have been competing: (1) inclusion of information during the model training or fine-tuning phase, stored in the model weights, and (2) integrating the LLM with an external knowledge source and leveraging the model’s reasoning capabilities for querying and synthesizing knowledge into comprehensible content, an approach known as Retrieval-Augmentation Generation (RAG) (Lewis et al., 2020). In the context of text summarization, we note a significant shift from the former method, generally associated with pre-trained encoder-decoder models, towards the latter (Retkowski, 2023), (Zhang et al., 2023), which involves large instruction-tuned autoregressive language models performing zero-shot prompting with functional tools such as LangChain (Chase, 2022) or LlamaIndex (Liu, 2022). Zero-shot summarization with instruction-tuned models provides improved trends.truthfulness, reduced hallucinations, and constant updates from an external data source, circumventing the expensive process of LLM re-training. Although standard evaluation frameworks for these tools are not yet accessible, studies suggest that the quality of LLM-generated summaries matches human-written summaries (Zhang et al., 2023). Of particular interest in the realm of summarization methodologies is Query-Based Text Summarization (QS), a unique approach that is rapidly evolving with the novel advancements in LLMs. Unlike traditional summarization, QS tailors the summary to a user-specified question (Yu, 2022)(Yang et al., 2023). As for general text summarization, predominantly pre-trained models have been deployed for QS, as reviewed in (Yu, 2022), pointing towards the exploration of zero-shot approaches as a promising path for future research.

RAG systems are designed to function in two sequential stages: the extraction of targeted and pertinent text from a large magnitude of curated content, and the generation, or synthesis, of a suitable response. In this context, QA and QS are both part of a continuum of LLM tasks aiming at providing succinct and informed responses. Yet pivotal differences between these tasks lie within the abundance of information retrieved from the text corpus and the complexity involved in the synthesis phase. For QA tasks, the response may be found directly within the text corpus, initiating the retrieval of narrow and specific text 'chunks' that are rephrased by the LLM to formulate the answer. Consequently, the precision of retrieval is paramount to deliver accurate and valid information. In contrast, QS tasks often require a broader pull of information that covers a wider spectrum of the query's nuances. Enhancements to the LLM's reasoning capability, coupled with an increased context length (up to 32K for GPT4 and 100k for Claude2), enables the ability to respond to more comprehensive queries across an extensive corpus such as Pubmed.

However, retrieving a larger amount of information into the synthesizer context presents a distinct challenge that needs to be addressed. Current LLM models are struggling to fully exploit all the retrieved content, e.g., multi-document question-answering performance is degraded as the context grows longer (Liu et al., 2023). While new attention-based neural architectures designed to deal with a very large context window may prevent performance drops (Yu et al., 2023), an efficient selection of the most relevant information has become critical, not least for the sake of latency, cost, and energy consumption. This challenge is particularly prevalent in the context of biomedical literature which contains extensively redundant pieces of information. This text corpus presents an information overload problem, where rare and recent yet important information can be dominated by over-represented older concepts.

In this study, leaving aside the generative side of RAG, we introduce a novel knowledge-graph-based retrieval approach that enables access to the long tail of biomedical knowledge. We demonstrate that RAG retrieval approaches, typically based on text chunk embedding similarity, leave out a significant proportion of relevant information because of the data imbalance in a queried text corpus such as Pubmed. Some over-represented topics can preclude the RAG synthesizer from accessing more recent discoveries by monopolizing the list of most similar text chunks. We propose to perform a rebalancing of the retrieved text chunks by under-sampling these larger clusters of information, and to do so by structuring the text corpus with a knowledge graph of biomedical entities (genes, diseases, and drugs). In addition, our method also provides control mechanisms to prioritize the retrieval of recent and impactful discoveries. Finally, we built a hybrid approach combining the strengths of LLM embedding semantic relationships and structured knowledge graph and show that it outperforms both embedding similarity and knowledge graph retrieval methods.edge graph based methods for biomedical information retrieval.

Related work

Knowledge Graphs (KGs) are structured knowledge models linking real-world or abstract concepts, or entities, with relationships in the form (head entity, relation, tail entity). KGs have been proposed to complement LLMs in various settings such as hallucination limitations (Ji et al., 2022)(Feng et al., 2023) and LLM interpretability (Lin et al., 2019). As reviewed in (Pan et al., 2023), KGs have also been combined with LLMs to enhance pre-training and inference (Zhang et al., 2019)(Yasunaga et al., 2021), and reciprocally LLMs have been leveraged to complement KG tasks such as entity embedding (Zhang et al., 2020), link prediction (Yao et al., 2019)(Xie et al., 2022) and KG construction (Bosselut et al., 2019)(Han et al., 2023).

To solve multiple-choice question-answering tasks, a group of models have combined question-answer text encodings with Graph Neural Network embeddings (GNN) of KG paths linking entities present in the question and candidate answers. The joint embedding of each candidate question-answer pair is attributed a plausibility score via a multilayer perceptron. Kag-Net (Lin et al., 2019) combines graph convolutional networks (Kipf and Welling, 2016) and LSTMs (Hochreiter and Schmidhuber, 1997) to solve multiple-choice question answering. It feeds KG multi-hop paths linking pairs of question entities and candidate answer entities into an attention-based GCN to attribute a plausibility score to each pair. Similarly, MH-GRN (Feng et al., 2020), QA-GNN (Yasunaga et al., 2021), JointLK (Sun et al., 2021), and GreaseLM (Zhang et al., 2022) combine GNN embeddings of the KG question-answer entity subgraphs with an LLM embedding of the question produced by an encoder-only transformer LLM such as RoBERTA (Liu et al., 2019). These hybrid graph-text encoding models are all trained on multiple-choice QA datasets and lack capabilities to generate natural language responses to queries.

Pre-transformer-era model KGLM is an autoregressive language model leveraging LSTMs to define a probability distribution for the next token (Logan et al., 2019). Each predicted token is taken among the entities of a knowledge graph by mapping the "prompt" sequence to the most likely parent entity and relation. KGLM is also able to learn a local knowledge graph made of new entities if unseen in its training set. This approach is reminiscent of the knowledge graph index implemented in the LlamaIndex package (Liu, 2022). A KG index is built by extracting (subject, predicate, object) triplets from a text corpus using an autoregressive LLM (defaulting to OpenAI completion endpoint). For each user question, keywords are then extracted using the same LLM and used to retrieve triplets in the k-hop neighborhood of the keywords. The retrieved triplets are then added to the synthesizer context for answer generation.

To the best of our knowledge, this study is the first to highlight the information overload problem in the context of text chunk embedding similarity retrieval and to propose a graph-distance retrieval approach to mitigate its effect.

Methods

A typical information retrieval (IR) workflow is composed of two sequential steps: the retrieval step and the synthesis step. The former aims at retrieving text chunks that share a relationship with the user question and the latter combine the retrieved context and the user question in its prompt to produce an answer. In this section, we detail two alternative approaches to perform the retrieval step:

• IR using a similarity function between dense embeddings of the user question and the text corpus.

• IR using a novel Knowledge-Graph approach relying on entity recognition and relationship extraction performed with a model trained and fine-tuned for biomedical literature.

IR with text embedding similarity

We use text Embedding Similarity Information Retrieval (ES IR) as a baseline approach for this study.

Embedding indexing

We built an embedding index from a subs...For each experiment, a different subset was used and is specified in the associated experiment section (typically, about 100k documents were indexed per experiment). In all cases, each selected article’s title and abstract were split into individual sentences using en_core_sci_md, a sentence tokenizer trained on large biomedical dataset (Neumann et al., 2019). Embeddings for each sentence were obtained using OpenAI’s second generation embedding model text-embedding-ada-002. Each embedding is encoded into a 1536-dimension vector. While little is known about OpenAI’s embedding model specifications, text-embedding-ada-002 ranks among the top-8 retrieval text embedding models on scientific facts benchmark (e.g. SciFact benchmark on MTEB2), offers a larger input size (8191 tokens) and showed clear semantic pattern on the datasets analyzed in this study. In very rare occasions (<.01%), a sentence would be longer than the embedding model input token limit. Those sentences were split to fit the limit.

Retrieval

While complex approaches have been developed, e.g. MaxSim (Khattab and Zaharia, 2020), most ES IR strategies rely on either cosine/inner-product or Euclidean similarity function to retrieve the text chunks whose embeddings are the most similar to the user question embedding vector (Wang, 2022). In this study, we use cosine similarity to rank the embedded text chunks for each query. Various retrieval rank thresholds were used in this study and are specified in the experiment section.

IR with knowledge graph support

The rationale behind using a knowledge graph for IR is that traditional text embedding similarity approaches are limited by the imbalance of pieces of information in a large corpus of text such as Pubmed. Some topics have been documented in greater length than others. While topics are often over-represented because of their importance for a field information (e.g. the EGFR drug target is referenced in more than 84k+ articles related to cancer), they can hide other relevant information by their sheer number when semantic similarity is used for retrieval. Rebalancing the retrievable text chunks can be done by undersampling the larger clusters of information. The problem then becomes how to define these clusters. While these clusters could be defined by the text chunk distributions in semantic space, a domain knowledge...or the embedding index onto the nodes and edges of the knowledge graph. The following rules were applied to perform the mapping: Only text chunks with at least one annotation are mapped. Text chunks with a single annotated entity are associated with the node of that entity. Text chunks with two annotated entities are associated with the corresponding edge if the pair has been labeled by the RE model. Text chunks with two annotated entities are associated with both entity nodes if the pair has not been labeled by the RE model. Previous two rules are applied to all combinatorial entity pairs in text chunks with 3+ entities. Once text chunks have been mapped to the knowledge graph, we can exploit graph distances to retrieve the chunks that are the most relevant to the user question. The first step is to identify which entity(ies) are the starting point of the graph-based retrieval. We leverage the KAZU pipeline to identify which entities are present in the user question. We then build the shortest path relating these entities in the graph and retrieve text chunks mapped to the shortest path entities and their neighbor edges. This approach allows the synthesizer LLM to produce non-trivial answers. For example, if a question asks to explain the relationship between two entities whose interaction has not been directly documented in the literature, text chunks from intermediate entities are presented and allows to build an indirect explanation that may potentially lead to new discoveries. Yet, this approach by itself is still incomplete as it lacks a text chunks prioritization metric. Indeed, hundreds of thousands of text chunks may be mapped along the shortest path in the graph.A scientific article is annotated by extracting entities (NER) and the type of relationships linking entities (RE). Each sentence containing 1+ entity is mapped onto the knowledge graph, either on a link related two entities if it contains two entities that are linked semantically (+ sign) or to its individual entities otherwise (× sign). To prioritize the most relevant text chunks and enable a rebalancing of the data that gives a fair chance to each concept mapped along the shortest path, we introduce a scoring metric that factors in both the recency and the impact of a text chunk. We measure the impact of a text chunk as the total number of citations that the associated document received. Because recent articles have fewer citations but are more likely to contain new discoveries, we solve the trade-off between these two objectives by using the Pareto front of the recency/impact space. The algorithm is detailed in Algorithm 1. The ranking algorithm combined with the graph-distance approach enables to satisfy the main criterion we identified as key for improving upon embedding similarity retrieval, i.e. data rebalancing giving an equal chance to each entity related to a question, while also surfacing latest significant discoveries. Optional adjustable exclusion thresholds for minimum year of publication and minimum number of publications have been implemented in order to favor a higher quality source of information. These filters are not used in this study as we should apply them simultaneously to the embedding index for a fair comparison.he long tail of biomedical knowledge by leveraging the structured relationships between entities in the knowledge graph. This enables KG IR to retrieve relevant information that may not be easily accessible through traditional embedding similarity approaches. By mapping text chunks to entities and entity edges in the knowledge graph, KG IR can provide a more comprehensive and nuanced understanding of the relationships between different concepts in biomedical literature.

The gold-standard dataset used for evaluation included curated annotations from the National Library of Medicine (NLM) and GeneRIF annotations for potential drug targets related to specific diseases. While these annotations may not cover all articles in the corpus, they served as a benchmark for evaluating the performance of both KG IR and ES IR. The metrics precision@K and recall@K were used to assess the retrieval performance of both approaches.

Overall, KG IR demonstrated superior performance compared to ES IR, particularly in terms of recall. KG IR was able to retrieve a higher percentage of gold-standard documents for a given retrieval volume, indicating its effectiveness in capturing relevant information. As the retrieval window increased, ES IR showed a peak precision value at K=250 but was outperformed by KG IR in terms of recall. KG IR's ability to access the structured relationships in the knowledge graph allowed it to access a broader range of biomedical knowledge, leading to better retrieval performance in this context.

In conclusion, the structured nature of the knowledge graph and its ability to capture complex relationships between entities in biomedical literature make it a powerful tool for information retrieval in the biomedical domain. KG IR's performance highlights the importance of leveraging structured data and domain-specific knowledge for improving the effectiveness of information retrieval systems in biomedical research.is results in a limited exploration of the diverse concepts present in the corpus, leading to suboptimal retrieval performance. In contrast, KG IR, leveraging the structured relationships in the knowledge graph, is able to access the long tail of biomedical knowledge and retrieve information from a broader range of concepts, as demonstrated by the higher recall rates.

The landscape projection of the embedding space revealed distinct patterns corresponding to different disease areas and types of entities expressed in the text chunks. Disease areas were localized in specific regions of the embedding space, and different types of entities such as genes, chemical compounds/drugs, and diseases exhibited characteristic patterns. By overlaying the landscape with cosine similarity between the question embedding and the text corpus embeddings, it was evident that ES IR primarily retrieved text chunks from the vicinity of the question embedding, potentially limiting its ability to capture diverse concepts relevant to the query.

The gold-standard and local knowledge graph metrics for each disease explored in the retrieval comparison highlighted the differences in the retrieval performance of ES IR and KG IR across different therapeutic areas. KG IR demonstrated a better ability to capture relevant information related to the diseases, as evidenced by the higher number of articles, chunks, and genes retrieved from the 1-hop neighborhood in the knowledge graph compared to the curated dataset used for evaluation.

Overall, the findings suggest that the structured nature of the knowledge graph and its capability to access a wide range of biomedical knowledge play a crucial role in enhancing information retrieval performance in the biomedical domain. By effectively leveraging the relationships between entities in the knowledge graph, KG IR can overcome the limitations of traditional embedding similarity approaches and provide a more comprehensive and nuanced understanding of the complex biomedical concepts present in the corpus.e balancing in KG IR allows it to explore a wider range of concepts and retrieve information from diverse regions of the embedding space. The comparison between ES IR and KG IR retrieval regions in the landscape projection highlighted the localized nature of ES IR retrieval and the multipolar distribution of KG IR retrieval, indicating the effectiveness of data balancing in accessing long-tail knowledge.

By combining the strengths of both semantic and graph-based retrieval approaches, a hybrid ranking system, termed Hybrid IR, was proposed. This approach leverages the quantitative ranking scores of both ES IR and KG IR to rescale and average the scores for each text chunk, resulting in improved retrieval performance. Evaluation results demonstrated that Hybrid IR outperformed both ES IR and KG IR, especially for smaller volumes of retrieved information, showcasing the complementary nature of the two methods.

In conclusion, the study emphasizes the importance of balanced and unbiased information retrieval in specialized domains such as biomedical research. Leveraging knowledge graph-based retrieval systems alongside embedding similarity approaches can enhance the overall performance of information retrieval systems, enabling the extraction of long-tail biomedical knowledge effectively. The hybrid approach combining semantic and graph-based methods offers a promising direction for maximizing retrieval performance and capturing a diverse range of concepts in biomedical information processing.eration tasks is still being explored, it holds promise for enhancing text generation systems by leveraging the structured knowledge in knowledge graphs. The integration of knowledge graphs into large language models (LLMs) has shown improvements in text synthesis quality, making the generated content more factual, diverse, and specific. This approach has the potential to enhance answer generation tasks by accessing long-tail biomedical information, although the impact on signal-to-noise ratio needs to be carefully managed.

Furthermore, utilizing LLM capabilities like "chain of thoughts (COT)" could aid in filtering out irrelevant entities and directing entity mapping to the knowledge graph for retrieving additional contextual information. COT-directed reasoning and answer generation may be particularly beneficial for complex questions requiring multi-hop retrieval or sub-graph identification, offering a potential avenue for future research to enhance content generation performance.

While this study focused on biomedical information retrieval, similar knowledge graph-based reasoning and generation approaches are actively researched in open-domain contexts as well. The mutual complementarity of semantic and graph-based retrieval methods, as demonstrated in this study, highlights the potential for hybrid systems to outperform individual approaches, contributing to the advancement of information retrieval and synthesis in specialized domains.Generation scenarios are diverse and while the collection of graph-text parallel corpus is challenging and costly, resulting in low training fidelity and poor generation quality. In this study, a weakly supervised knowledge graph (KG) was constructed from journal articles in free text format, allowing for the creation of a domain-specific graph-text parallel corpus. A potential future research direction could involve applying the Reverse Adversarial Generation (RAG) model for direct text generation from relevant graph entities. This accurate generation from the KG could have significant implications for applications such as automated authoring of scientific articles and regulatory submissions.

References:
- Aronson AR, Bodenreider O, Chang HF, Humphrey SM, Mork JG, Nelson SJ, Rindflesch TC, Wilbur WJ. 2000. The nlm indexing initiative.
- Bosselut A, Rashkin H, Sap M, Malaviya C, Celikyilmaz A, Choi Y. 2019. Comet: Commonsense transformers for automatic knowledge graph construction.
- Chase H. 2022. Langchain.
- Feng S, Balachandran V, Bai Y, Tsvetkov Y. 2023. Factkb: Generalizable factuality evaluation using language models enhanced with factual knowledge.
- Feng Y, Chen X, Lin BY, Wang P, Yan J, Ren X. 2020. Scalable multi-hop relational reasoning for knowledge-aware question answering.
- Gu Y, Tinn R, Cheng H, Lucas M, Usuyama N, Liu X, Naumann T, Gao J, Poon H. 2020. Domain-specific language model pretraining for biomedical natural language processing.
- Guu K, Lee K, Tung Z, Pasupat P, Chang MW. 2020. Realm: Retrieval-augmented language model pre-training.
- Han J, Collier N, Buntine W, Shareghi E. 2023. Pive: Prompting with iterative verification improving graph-based generative capability of llms.
- Hochreiter S, Schmidhuber J. 1997. Long short-term memory.
- Ji Z, Liu Z, Lee N, Yu T, Wilie B, Zeng M, Fung P. 2022. Rho (ρ): Reducing hallucination in open-domain dialogues with knowledge grounding.
- Ke P, Ji H, Ran Y, Cui X, Wang L, Song L, Zhu X, Huang M. 2021. Jointgt: Graph-text joint representation learning for text generation from knowledge graphs.
- Khattab O, Zaharia M. 2020. Colbert: Efficient and effective passage search via contextualized late interaction over bert.
- Kipf TN, Welling M. 2016. Semi-supervised classification with graph convolutional networks.
- Lewis P, Perez E, Piktus A, Petroni F, Karpukhin V, Goyal N, Küttler H, Lewis M, Yih WT, Rocktäschel T, Riedel S, Kiela D. 2020. Retrieval-augmented generation for knowledge-intensive nlp tasks.Lin BY, Chen X, Chen J, Ren X. 2019. Kagnet: Knowledge-aware graph networks for commonsense reasoning.  
Liu J. 2022. Llamaindex.  
Liu NF, Lin K, Hewitt J, Paranjape A, Bevilacqua M, Petroni F, Liang P. 2023. Lost in the middle: How language models use long contexts.  
Liu Y, Ott M, Goyal N, Du J, Joshi M, Chen D, Levy O, Lewis M, Zettlemoyer L, Stoyanov V, Allen PG. 2019. Roberta: A robustly optimized bert pretraining approach.  
Logan RL, Liu NF, Peters ME, Gardner M, Singh S. 2019. Barack’s wife hillary: Using knowledge-graphs for fact-aware language modeling.  
Luo L, Lai PT, Wei CH, Arighi CN, Lu Z. 2022. Biored: a rich biomedical relation extraction dataset.  
Neumann M, King D, Beltagy I, Ammar W. 2019. Scispacy: Fast and robust models for biomedical natural language processing.  
Pan S, Member S, Luo L, Wang Y, Chen C, Wang J, Wu X. 2023. Unifying large language models and knowledge graphs: A roadmap.  
Retkowski F. 2023. The current state of summarization.  
Ribeiro LF, Schmitt M, Schütze H, Gurevych I. 2020. Investigating pretrained language models for graph-to-text generation.  
Sun Y, Shi Q, Qi L, Zhang Y. 2021. Jointlk: Joint reasoning with language models and knowledge graphs for commonsense question answering.  
Sung M, Jeong M, Choi Y, Kim D, Lee J, Kang J. 2022. Bern2: an advanced neural biomedical named entity recognition and normalization tool.  
Wang Y. 2022. A survey on efficient processing of similarity queries over neural embeddings.  
Xie X, Zhang N, Li Z, Deng S, Chen H, Xiong F, Chen M, Chen H. 2022. From discrimination to generation: Knowledge graph completion with generative transformer.  
Yang X, Li Y, Zhang X, Chen H, Cheng W. 2023. Exploring the limits of chatgpt for query or aspect-based text summarization.  
Yao L, Mao C, Luo Y. 2019. Kg-bert: Bert for knowledge graph completion.  
Yasunaga M, Ren H, Bosselut A, Liang P, Leskovec J. 2021. Qa-gnn: Reasoning with language models and knowledge graphs for question answering.  
Yoon W, Jackson R, Ford E, Poroshin V, Kang J. 2022. Biomedical ner for the enterprise with distillated bern2 and the kazu framework.  
Yu H. 2022. Survey of query-based.Yu L, Simig D, Flaherty C, Aghajanyan A, Zettlemoyer L, Lewis M. 2023. Megabyte: Predicting million-byte sequences with multiscale transformers.  
Zhang T, Ladhak F, Durmus E, Liang P, McKeown K, Hashimoto TB. 2023. Benchmarking large language models for news summarization.  
Zhang X, Bosselut A, Yasunaga M, Ren H, Liang P, Manning CD, Leskovec J. 2022. Greaselm: Graph reasoning enhanced language models for question answering.  
Zhang Z, Han X, Liu Z, Jiang X, Sun M, Liu Q. 2019. Ernie: Enhanced language representation with informative entities.  
Zhang Z, Liu X, Zhang Y, Su Q, Sun X, He B. 2020. Pretrain-kge: Learning knowledge representation from pretrained language models.  
Zhou H, Young T, Huang M, Zhao H, Xu J, Zhu X. 2018. Commonsense knowledge aware conversation generation with graph attention.